{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"col-md-12 col-sm-12\">\n",
      " <h2 class=\"news-head\">\n",
      "  <span>\n",
      "   Top Headlines\n",
      "  </span>\n",
      " </h2>\n",
      " <h3 class=\"news-page-feature\">\n",
      "  <a href=\"/india/story/hindi-language-row-kiren-rijiju-chidambaram-yediyurappa-1599784-2019-09-16\" title=\"Hindi imposition row: Rijiju tweets old video of Chidambaram on common language\">\n",
      "   Hindi imposition row: Rijiju tweets old video of Chidambaram on common language\n",
      "  </a>\n",
      " </h3>\n",
      " <h3 class=\"news-page-feature\">\n",
      "  <a href=\"/crime/story/gujarat-old-man-impersonate-delhi-airport-makeup-billu-barber-1599776-2019-09-16\" title=\"Billu Barber who helped Gujarati man impersonate 80yr-old arrested in Delhi\">\n",
      "   Billu Barber who helped Gujarati man impersonate 80yr-old arrested in Delhi\n",
      "  </a>\n",
      " </h3>\n",
      " <h3 class=\"news-page-feature\">\n",
      "  <a href=\"/trending-news/story/indigo-forgets-luggage-of-entire-delhi-to-istanbul-flight-internet-explodes-1599791-2019-09-16\" title=\"IndiGo forgets Delhi-Istanbul flight luggage. Internet explodes\">\n",
      "   IndiGo forgets Delhi-Istanbul flight luggage. Internet explodes\n",
      "  </a>\n",
      " </h3>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"https://www.indiatoday.in/news.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "top_headlines = soup.find(id=\"page\")\n",
    "forecast_items = top_headlines.find_all(class_=\"col-md-12 col-sm-12\")\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())\n",
    "h=tonight.prettify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "  \n",
      "   Top Headlines\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      "   Hindi imposition row: Rijiju tweets old video of Chidambaram on common language\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      "   Billu Barber who helped Gujarati man impersonate 80yr-old arrested in Delhi\n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      "   IndiGo forgets Delhi-Istanbul flight luggage. Internet explodes\n",
      "  \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(tonight)\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "files=cleanhtml(h)\n",
    "f1=open('newsdoc1.txt','w',errors='ignore')\n",
    "f1.write(files)\n",
    "f1.close()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=word_tokenize(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top',\n",
       " 'Headlines',\n",
       " 'Hindi',\n",
       " 'imposition',\n",
       " 'row',\n",
       " ':',\n",
       " 'Rijiju',\n",
       " 'tweets',\n",
       " 'old',\n",
       " 'video',\n",
       " 'of',\n",
       " 'Chidambaram',\n",
       " 'on',\n",
       " 'common',\n",
       " 'language',\n",
       " 'Billu',\n",
       " 'Barber',\n",
       " 'who',\n",
       " 'helped',\n",
       " 'Gujarati',\n",
       " 'man',\n",
       " 'impersonate',\n",
       " '80yr-old',\n",
       " 'arrested',\n",
       " 'in',\n",
       " 'Delhi',\n",
       " 'IndiGo',\n",
       " 'forgets',\n",
       " 'Delhi-Istanbul',\n",
       " 'flight',\n",
       " 'luggage',\n",
       " '.',\n",
       " 'Internet',\n",
       " 'explodes']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#word_tokens = word_tokenize(a)\n",
    "word_tokens=a\n",
    "punc=['.',',',':','?',';','(',')']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(',\n",
       " ')',\n",
       " ',',\n",
       " '.',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words.union(punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8adf3a7c513e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfiltered\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'filtered' is not defined"
     ]
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sent = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sent = [w for w in word_tokens if not w in punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top',\n",
       " 'Headlines',\n",
       " 'Hindi',\n",
       " 'imposition',\n",
       " 'row',\n",
       " 'Rijiju',\n",
       " 'tweets',\n",
       " 'old',\n",
       " 'video',\n",
       " 'of',\n",
       " 'Chidambaram',\n",
       " 'on',\n",
       " 'common',\n",
       " 'language',\n",
       " 'Billu',\n",
       " 'Barber',\n",
       " 'who',\n",
       " 'helped',\n",
       " 'Gujarati',\n",
       " 'man',\n",
       " 'impersonate',\n",
       " '80yr-old',\n",
       " 'arrested',\n",
       " 'in',\n",
       " 'Delhi',\n",
       " 'IndiGo',\n",
       " 'forgets',\n",
       " 'Delhi-Istanbul',\n",
       " 'flight',\n",
       " 'luggage',\n",
       " 'Internet',\n",
       " 'explodes']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in filtered_sent:\n",
    "    count=count+1\n",
    "#filtered_sent=' '.filtered_sent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python code to find frequency of each word \n",
    "def freq(str): \n",
    "  \n",
    "    # break the string into list of words  \n",
    "    #str = str.split()          \n",
    "    str2 = [] \n",
    "  \n",
    "    # loop till string values present in list str \n",
    "    for i in str:              \n",
    "  \n",
    "        # checking for the duplicacy \n",
    "        if i not in str2: \n",
    "  \n",
    "            # insert value in str2 \n",
    "            str2.append(i)  \n",
    "              \n",
    "    for i in range(0, len(str2)): \n",
    "  \n",
    "        # count the frequency of each word(present  \n",
    "        # in str2) in str and print \n",
    "        print('Frequency of', str2[i], 'is :', str.count(str2[i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of Top is : 1\n",
      "Frequency of Headlines is : 1\n",
      "Frequency of Hindi is : 1\n",
      "Frequency of imposition is : 1\n",
      "Frequency of row is : 1\n",
      "Frequency of Rijiju is : 1\n",
      "Frequency of tweets is : 1\n",
      "Frequency of old is : 1\n",
      "Frequency of video is : 1\n",
      "Frequency of of is : 1\n",
      "Frequency of Chidambaram is : 1\n",
      "Frequency of on is : 1\n",
      "Frequency of common is : 1\n",
      "Frequency of language is : 1\n",
      "Frequency of Billu is : 1\n",
      "Frequency of Barber is : 1\n",
      "Frequency of who is : 1\n",
      "Frequency of helped is : 1\n",
      "Frequency of Gujarati is : 1\n",
      "Frequency of man is : 1\n",
      "Frequency of impersonate is : 1\n",
      "Frequency of 80yr-old is : 1\n",
      "Frequency of arrested is : 1\n",
      "Frequency of in is : 1\n",
      "Frequency of Delhi is : 1\n",
      "Frequency of IndiGo is : 1\n",
      "Frequency of forgets is : 1\n",
      "Frequency of Delhi-Istanbul is : 1\n",
      "Frequency of flight is : 1\n",
      "Frequency of luggage is : 1\n",
      "Frequency of Internet is : 1\n",
      "Frequency of explodes is : 1\n"
     ]
    }
   ],
   "source": [
    "freq(filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "ps = PorterStemmer()\n",
    "stemmed_filtered_sent=[]\n",
    "for w in filtered_sent:\n",
    "    b=ps.stem(w)\n",
    "    stemmed_filtered_sent.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['top',\n",
       " 'headlin',\n",
       " 'hindi',\n",
       " 'imposit',\n",
       " 'row',\n",
       " 'rijiju',\n",
       " 'tweet',\n",
       " 'old',\n",
       " 'video',\n",
       " 'of',\n",
       " 'chidambaram',\n",
       " 'on',\n",
       " 'common',\n",
       " 'languag',\n",
       " 'billu',\n",
       " 'barber',\n",
       " 'who',\n",
       " 'help',\n",
       " 'gujarati',\n",
       " 'man',\n",
       " 'imperson',\n",
       " '80yr-old',\n",
       " 'arrest',\n",
       " 'in',\n",
       " 'delhi',\n",
       " 'indigo',\n",
       " 'forget',\n",
       " 'delhi-istanbul',\n",
       " 'flight',\n",
       " 'luggag',\n",
       " 'internet',\n",
       " 'explod']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "d=[]\n",
    "for i in filtered_sent:\n",
    "    d.append([stemmed_filtered_sent[k],i])\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['top', 'Top'],\n",
       " ['headlin', 'Headlines'],\n",
       " ['hindi', 'Hindi'],\n",
       " ['imposit', 'imposition'],\n",
       " ['row', 'row'],\n",
       " ['rijiju', 'Rijiju'],\n",
       " ['tweet', 'tweets'],\n",
       " ['old', 'old'],\n",
       " ['video', 'video'],\n",
       " ['of', 'of'],\n",
       " ['chidambaram', 'Chidambaram'],\n",
       " ['on', 'on'],\n",
       " ['common', 'common'],\n",
       " ['languag', 'language'],\n",
       " ['billu', 'Billu'],\n",
       " ['barber', 'Barber'],\n",
       " ['who', 'who'],\n",
       " ['help', 'helped'],\n",
       " ['gujarati', 'Gujarati'],\n",
       " ['man', 'man'],\n",
       " ['imperson', 'impersonate'],\n",
       " ['80yr-old', '80yr-old'],\n",
       " ['arrest', 'arrested'],\n",
       " ['in', 'in'],\n",
       " ['delhi', 'Delhi'],\n",
       " ['indigo', 'IndiGo'],\n",
       " ['forget', 'forgets'],\n",
       " ['delhi-istanbul', 'Delhi-Istanbul'],\n",
       " ['flight', 'flight'],\n",
       " ['luggag', 'luggage'],\n",
       " ['internet', 'Internet'],\n",
       " ['explod', 'explodes']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top',\n",
       " 'Headlines',\n",
       " 'Hindi',\n",
       " 'imposition',\n",
       " 'row',\n",
       " 'Rijiju',\n",
       " 'tweets',\n",
       " 'old',\n",
       " 'video',\n",
       " 'of',\n",
       " 'Chidambaram',\n",
       " 'on',\n",
       " 'common',\n",
       " 'language',\n",
       " 'Billu',\n",
       " 'Barber',\n",
       " 'who',\n",
       " 'helped',\n",
       " 'Gujarati',\n",
       " 'man',\n",
       " 'impersonate',\n",
       " '80yr-old',\n",
       " 'arrested',\n",
       " 'in',\n",
       " 'Delhi',\n",
       " 'IndiGo',\n",
       " 'forgets',\n",
       " 'Delhi-Istanbul',\n",
       " 'flight',\n",
       " 'luggage',\n",
       " 'Internet',\n",
       " 'explodes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of top is : 1\n",
      "Frequency of headlin is : 1\n",
      "Frequency of hindi is : 1\n",
      "Frequency of imposit is : 1\n",
      "Frequency of row is : 1\n",
      "Frequency of rijiju is : 1\n",
      "Frequency of tweet is : 1\n",
      "Frequency of old is : 1\n",
      "Frequency of video is : 1\n",
      "Frequency of of is : 1\n",
      "Frequency of chidambaram is : 1\n",
      "Frequency of on is : 1\n",
      "Frequency of common is : 1\n",
      "Frequency of languag is : 1\n",
      "Frequency of billu is : 1\n",
      "Frequency of barber is : 1\n",
      "Frequency of who is : 1\n",
      "Frequency of help is : 1\n",
      "Frequency of gujarati is : 1\n",
      "Frequency of man is : 1\n",
      "Frequency of imperson is : 1\n",
      "Frequency of 80yr-old is : 1\n",
      "Frequency of arrest is : 1\n",
      "Frequency of in is : 1\n",
      "Frequency of delhi is : 1\n",
      "Frequency of indigo is : 1\n",
      "Frequency of forget is : 1\n",
      "Frequency of delhi-istanbul is : 1\n",
      "Frequency of flight is : 1\n",
      "Frequency of luggag is : 1\n",
      "Frequency of internet is : 1\n",
      "Frequency of explod is : 1\n"
     ]
    }
   ],
   "source": [
    "freq(stemmed_filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.update(\"mufti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'f',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'u',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'f',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'u',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.add('Mufti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mufti',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'f',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'u',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in filtered_sent:\n",
    "    if i in stop_words:\n",
    "        filtered_sent.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top',\n",
       " 'Headlines',\n",
       " 'Hindi',\n",
       " 'imposition',\n",
       " 'row',\n",
       " 'Rijiju',\n",
       " 'tweets',\n",
       " 'old',\n",
       " 'video',\n",
       " 'Chidambaram',\n",
       " 'common',\n",
       " 'language',\n",
       " 'Billu',\n",
       " 'Barber',\n",
       " 'helped',\n",
       " 'Gujarati',\n",
       " 'man',\n",
       " 'impersonate',\n",
       " '80yr-old',\n",
       " 'arrested',\n",
       " 'Delhi',\n",
       " 'IndiGo',\n",
       " 'forgets',\n",
       " 'Delhi-Istanbul',\n",
       " 'flight',\n",
       " 'luggage',\n",
       " 'Internet',\n",
       " 'explodes']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New Stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"hotTopic clearfix\">\n",
      " <div class=\"section-blog-left-img\">\n",
      "  <figure>\n",
      "   <a href=\"https://www.news18.com/news/india/will-personally-check-if-required-cji-says-ready-to-visit-jk-to-assess-ground-situation-after-art-370-move-2310499.html\">\n",
      "    <picture>\n",
      "     <source media=\"(min-width: 1280px)\" srcset=\"https://images.news18.com/optimize/kBL7bVg-L0ShWmNb48wianXPPM8=/589x391/images.news18.com/ibnlive/uploads/589x391/jpg/2019/01/ranjan-gogoi.jpg\"/>\n",
      "     <source media=\"(min-width: 320px)\" srcset=\"https://images.news18.com/optimize/rkNz9HBMLI8ShFiqTJWeUyDZPhY=/290x192/images.news18.com/ibnlive/uploads/290x192/jpg/2019/01/ranjan-gogoi.jpg\"/>\n",
      "     <img alt=\"'Will Personally Check if Required': CJI Says Ready to Visit J&amp;K to Assess Situation After Article 370 Move\" srcset=\"https://images.news18.com/optimize/kBL7bVg-L0ShWmNb48wianXPPM8=/589x391/images.news18.com/ibnlive/uploads/589x391/jpg/2019/01/ranjan-gogoi.jpg\" title=\"'Will Personally Check if Required': CJI Says Ready to Visit J&amp;K to Assess Situation After Article 370 Move\"/>\n",
      "    </picture>\n",
      "   </a>\n",
      "   <div class=\"title-content\">\n",
      "    <h1>\n",
      "     <a href=\"https://www.news18.com/news/india/will-personally-check-if-required-cji-says-ready-to-visit-jk-to-assess-ground-situation-after-art-370-move-2310499.html\">\n",
      "      'Will Personally Check if Required': CJI Says Ready to Visit J&amp;K to Assess Situation After Article 370 Move\n",
      "     </a>\n",
      "    </h1>\n",
      "   </div>\n",
      "  </figure>\n",
      " </div>\n",
      " <div class=\"section-blog-left-img-list\">\n",
      "  <ul>\n",
      "   <li>\n",
      "    <a href=\"https://www.news18.com/news/india/month-after-ruling-out-mediation-in-ayodhya-case-panel-seeks-scs-view-on-resumption-of-talks-2310719.html\">\n",
      "     Month After Ruling Out Mediation in Ayodhya Case, Panel Seeks SC's View on Resumption of Talks\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    <a href=\"https://www.news18.com/news/india/former-jk-cm-farooq-abdullah-detained-under-draconian-public-safety-act-2310441.html\">\n",
      "     Farooq Abdullah, Under House Arrest Since August, Detained Under Stringent Public Safety Act\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    <a href=\"https://www.news18.com/news/india/no-56-can-stop-you-in-letter-to-chidambaram-on-74th-birthday-karti-takes-a-dig-at-govt-2310235.html\">\n",
      "     'No 56 Can Stop You': In Tihar Jail, Chidambaram Gets Birthday Letter from Son Karti\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    <a href=\"https://www.news18.com/news/india/the-fake-encounter-specialist-who-got-away-with-sexual-crimes-until-he-kidnapped-a-chennai-woman-2310389.html\">\n",
      "     The Fake Encounter Specialist Who Got Away With Sex Crimes Until He Kidnapped a Chennai Woman\n",
      "    </a>\n",
      "   </li>\n",
      "   <li>\n",
      "    <a href=\"https://www.news18.com/news/india/bloodbath-shootouts-bitter-rivalries-why-delhi-gangsters-are-on-a-killing-spree-never-witnessed-before-2310187.html\">\n",
      "     Bloodbath, Shootouts, Bitter Rivalries: Why Delhi Gangsters are on a Killing Spree Never Seen Before\n",
      "    </a>\n",
      "   </li>\n",
      "  </ul>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "page = requests.get(\"https://www.news18.com/india/\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "top_headlines = soup.find(id=\"main\")\n",
    "forecast_items = top_headlines.find_all(class_=\"hotTopic clearfix\")\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())\n",
    "h=tonight.prettify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "  \n",
      "   \n",
      "    \n",
      "     \n",
      "     \n",
      "     \n",
      "    \n",
      "   \n",
      "   \n",
      "    \n",
      "     \n",
      "      'Will Personally Check if Required': CJI Says Ready to Visit J&amp;K to Assess Situation After Article 370 Move\n",
      "     \n",
      "    \n",
      "   \n",
      "  \n",
      " \n",
      " \n",
      "  \n",
      "   \n",
      "    \n",
      "     Month After Ruling Out Mediation in Ayodhya Case, Panel Seeks SC's View on Resumption of Talks\n",
      "    \n",
      "   \n",
      "   \n",
      "    \n",
      "     Farooq Abdullah, Under House Arrest Since August, Detained Under Stringent Public Safety Act\n",
      "    \n",
      "   \n",
      "   \n",
      "    \n",
      "     'No 56 Can Stop You': In Tihar Jail, Chidambaram Gets Birthday Letter from Son Karti\n",
      "    \n",
      "   \n",
      "   \n",
      "    \n",
      "     The Fake Encounter Specialist Who Got Away With Sex Crimes Until He Kidnapped a Chennai Woman\n",
      "    \n",
      "   \n",
      "   \n",
      "    \n",
      "     Bloodbath, Shootouts, Bitter Rivalries: Why Delhi Gangsters are on a Killing Spree Never Seen Before\n",
      "    \n",
      "   \n",
      "  \n",
      " \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(tonight)\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext\n",
    "files2=cleanhtml(h)\n",
    "print(files2)\n",
    "f2=open('newsdoc2.txt','w',errors='ignore')\n",
    "f2.write(files2)\n",
    "f2.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=word_tokenize(files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#word_tokens = word_tokenize(a)\n",
    "word_tokens=a\n",
    "punc=[\".\",\",\",\":\",\"?\",\"'\",\";\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sent2 = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sent2 = [w for w in word_tokens if not w in punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'Will is : 1\n",
      "Frequency of Personally is : 1\n",
      "Frequency of Check is : 1\n",
      "Frequency of if is : 1\n",
      "Frequency of Required is : 1\n",
      "Frequency of CJI is : 1\n",
      "Frequency of Says is : 1\n",
      "Frequency of Ready is : 1\n",
      "Frequency of to is : 2\n",
      "Frequency of Visit is : 1\n",
      "Frequency of J is : 1\n",
      "Frequency of & is : 1\n",
      "Frequency of amp is : 1\n",
      "Frequency of K is : 1\n",
      "Frequency of Assess is : 1\n",
      "Frequency of Situation is : 1\n",
      "Frequency of After is : 2\n",
      "Frequency of Article is : 1\n",
      "Frequency of 370 is : 1\n",
      "Frequency of Move is : 1\n",
      "Frequency of Month is : 1\n",
      "Frequency of Ruling is : 1\n",
      "Frequency of Out is : 1\n",
      "Frequency of Mediation is : 1\n",
      "Frequency of in is : 1\n",
      "Frequency of Ayodhya is : 1\n",
      "Frequency of Case is : 1\n",
      "Frequency of Panel is : 1\n",
      "Frequency of Seeks is : 1\n",
      "Frequency of SC is : 1\n",
      "Frequency of 's is : 1\n",
      "Frequency of View is : 1\n",
      "Frequency of on is : 2\n",
      "Frequency of Resumption is : 1\n",
      "Frequency of of is : 1\n",
      "Frequency of Talks is : 1\n",
      "Frequency of Farooq is : 1\n",
      "Frequency of Abdullah is : 1\n",
      "Frequency of Under is : 2\n",
      "Frequency of House is : 1\n",
      "Frequency of Arrest is : 1\n",
      "Frequency of Since is : 1\n",
      "Frequency of August is : 1\n",
      "Frequency of Detained is : 1\n",
      "Frequency of Stringent is : 1\n",
      "Frequency of Public is : 1\n",
      "Frequency of Safety is : 1\n",
      "Frequency of Act is : 1\n",
      "Frequency of 'No is : 1\n",
      "Frequency of 56 is : 1\n",
      "Frequency of Can is : 1\n",
      "Frequency of Stop is : 1\n",
      "Frequency of You is : 1\n",
      "Frequency of In is : 1\n",
      "Frequency of Tihar is : 1\n",
      "Frequency of Jail is : 1\n",
      "Frequency of Chidambaram is : 1\n",
      "Frequency of Gets is : 1\n",
      "Frequency of Birthday is : 1\n",
      "Frequency of Letter is : 1\n",
      "Frequency of from is : 1\n",
      "Frequency of Son is : 1\n",
      "Frequency of Karti is : 1\n",
      "Frequency of The is : 1\n",
      "Frequency of Fake is : 1\n",
      "Frequency of Encounter is : 1\n",
      "Frequency of Specialist is : 1\n",
      "Frequency of Who is : 1\n",
      "Frequency of Got is : 1\n",
      "Frequency of Away is : 1\n",
      "Frequency of With is : 1\n",
      "Frequency of Sex is : 1\n",
      "Frequency of Crimes is : 1\n",
      "Frequency of Until is : 1\n",
      "Frequency of He is : 1\n",
      "Frequency of Kidnapped is : 1\n",
      "Frequency of a is : 2\n",
      "Frequency of Chennai is : 1\n",
      "Frequency of Woman is : 1\n",
      "Frequency of Bloodbath is : 1\n",
      "Frequency of Shootouts is : 1\n",
      "Frequency of Bitter is : 1\n",
      "Frequency of Rivalries is : 1\n",
      "Frequency of Why is : 1\n",
      "Frequency of Delhi is : 1\n",
      "Frequency of Gangsters is : 1\n",
      "Frequency of are is : 1\n",
      "Frequency of Killing is : 1\n",
      "Frequency of Spree is : 1\n",
      "Frequency of Never is : 1\n",
      "Frequency of Seen is : 1\n",
      "Frequency of Before is : 1\n"
     ]
    }
   ],
   "source": [
    "freq(filtered_sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique(list1): \n",
    "    l=[]\n",
    "    # intilize a null list \n",
    "    unique_list = [] \n",
    "      \n",
    "    # traverse for all elements \n",
    "    for x in list1: \n",
    "        # check if exists in unique_list or not \n",
    "        if x not in unique_list: \n",
    "            unique_list.append(x) \n",
    "    # print list \n",
    "    for x in unique_list: \n",
    "        l.append(x)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=unique(filtered_sent)\n",
    "f2=unique(filtered_sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top',\n",
       " 'Headlines',\n",
       " 'Hindi',\n",
       " 'imposition',\n",
       " 'row',\n",
       " 'Rijiju',\n",
       " 'tweets',\n",
       " 'old',\n",
       " 'video',\n",
       " 'Chidambaram',\n",
       " 'common',\n",
       " 'language',\n",
       " 'Billu',\n",
       " 'Barber',\n",
       " 'helped',\n",
       " 'Gujarati',\n",
       " 'man',\n",
       " 'impersonate',\n",
       " '80yr-old',\n",
       " 'arrested',\n",
       " 'Delhi',\n",
       " 'IndiGo',\n",
       " 'forgets',\n",
       " 'Delhi-Istanbul',\n",
       " 'flight',\n",
       " 'luggage',\n",
       " 'Internet',\n",
       " 'explodes']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Will\",\n",
       " 'Personally',\n",
       " 'Check',\n",
       " 'if',\n",
       " 'Required',\n",
       " 'CJI',\n",
       " 'Says',\n",
       " 'Ready',\n",
       " 'to',\n",
       " 'Visit',\n",
       " 'J',\n",
       " '&',\n",
       " 'amp',\n",
       " 'K',\n",
       " 'Assess',\n",
       " 'Situation',\n",
       " 'After',\n",
       " 'Article',\n",
       " '370',\n",
       " 'Move',\n",
       " 'Month',\n",
       " 'Ruling',\n",
       " 'Out',\n",
       " 'Mediation',\n",
       " 'in',\n",
       " 'Ayodhya',\n",
       " 'Case',\n",
       " 'Panel',\n",
       " 'Seeks',\n",
       " 'SC',\n",
       " \"'s\",\n",
       " 'View',\n",
       " 'on',\n",
       " 'Resumption',\n",
       " 'of',\n",
       " 'Talks',\n",
       " 'Farooq',\n",
       " 'Abdullah',\n",
       " 'Under',\n",
       " 'House',\n",
       " 'Arrest',\n",
       " 'Since',\n",
       " 'August',\n",
       " 'Detained',\n",
       " 'Stringent',\n",
       " 'Public',\n",
       " 'Safety',\n",
       " 'Act',\n",
       " \"'No\",\n",
       " '56',\n",
       " 'Can',\n",
       " 'Stop',\n",
       " 'You',\n",
       " 'In',\n",
       " 'Tihar',\n",
       " 'Jail',\n",
       " 'Chidambaram',\n",
       " 'Gets',\n",
       " 'Birthday',\n",
       " 'Letter',\n",
       " 'from',\n",
       " 'Son',\n",
       " 'Karti',\n",
       " 'The',\n",
       " 'Fake',\n",
       " 'Encounter',\n",
       " 'Specialist',\n",
       " 'Who',\n",
       " 'Got',\n",
       " 'Away',\n",
       " 'With',\n",
       " 'Sex',\n",
       " 'Crimes',\n",
       " 'Until',\n",
       " 'He',\n",
       " 'Kidnapped',\n",
       " 'a',\n",
       " 'Chennai',\n",
       " 'Woman',\n",
       " 'Bloodbath',\n",
       " 'Shootouts',\n",
       " 'Bitter',\n",
       " 'Rivalries',\n",
       " 'Why',\n",
       " 'Delhi',\n",
       " 'Gangsters',\n",
       " 'are',\n",
       " 'Killing',\n",
       " 'Spree',\n",
       " 'Never',\n",
       " 'Seen',\n",
       " 'Before']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!word |doc1| doc2!\n",
      "Top 1 0\n",
      "Headlines 1 0\n",
      "Hindi 1 0\n",
      "imposition 1 0\n",
      "row 1 0\n",
      "Rijiju 1 0\n",
      "tweets 1 0\n",
      "old 1 0\n",
      "video 1 0\n",
      "Chidambaram 1 1\n",
      "common 1 0\n",
      "language 1 0\n",
      "Billu 1 0\n",
      "Barber 1 0\n",
      "helped 1 0\n",
      "Gujarati 1 0\n",
      "man 1 0\n",
      "impersonate 1 0\n",
      "80yr-old 1 0\n",
      "arrested 1 0\n",
      "Delhi 1 1\n",
      "IndiGo 1 0\n",
      "forgets 1 0\n",
      "Delhi-Istanbul 1 0\n",
      "flight 1 0\n",
      "luggage 1 0\n",
      "Internet 1 0\n",
      "explodes 1 0\n",
      "'Will 0 1\n",
      "Personally 0 1\n",
      "Check 0 1\n",
      "if 0 1\n",
      "Required 0 1\n",
      "CJI 0 1\n",
      "Says 0 1\n",
      "Ready 0 1\n",
      "to 0 1\n",
      "Visit 0 1\n",
      "J 0 1\n",
      "& 0 1\n",
      "amp 0 1\n",
      "K 0 1\n",
      "Assess 0 1\n",
      "Situation 0 1\n",
      "After 0 1\n",
      "Article 0 1\n",
      "370 0 1\n",
      "Move 0 1\n",
      "Month 0 1\n",
      "Ruling 0 1\n",
      "Out 0 1\n",
      "Mediation 0 1\n",
      "in 0 1\n",
      "Ayodhya 0 1\n",
      "Case 0 1\n",
      "Panel 0 1\n",
      "Seeks 0 1\n",
      "SC 0 1\n",
      "'s 0 1\n",
      "View 0 1\n",
      "on 0 1\n",
      "Resumption 0 1\n",
      "of 0 1\n",
      "Talks 0 1\n",
      "Farooq 0 1\n",
      "Abdullah 0 1\n",
      "Under 0 1\n",
      "House 0 1\n",
      "Arrest 0 1\n",
      "Since 0 1\n",
      "August 0 1\n",
      "Detained 0 1\n",
      "Stringent 0 1\n",
      "Public 0 1\n",
      "Safety 0 1\n",
      "Act 0 1\n",
      "'No 0 1\n",
      "56 0 1\n",
      "Can 0 1\n",
      "Stop 0 1\n",
      "You 0 1\n",
      "In 0 1\n",
      "Tihar 0 1\n",
      "Jail 0 1\n",
      "Gets 0 1\n",
      "Birthday 0 1\n",
      "Letter 0 1\n",
      "from 0 1\n",
      "Son 0 1\n",
      "Karti 0 1\n",
      "The 0 1\n",
      "Fake 0 1\n",
      "Encounter 0 1\n",
      "Specialist 0 1\n",
      "Who 0 1\n",
      "Got 0 1\n",
      "Away 0 1\n",
      "With 0 1\n",
      "Sex 0 1\n",
      "Crimes 0 1\n",
      "Until 0 1\n",
      "He 0 1\n",
      "Kidnapped 0 1\n",
      "a 0 1\n",
      "Chennai 0 1\n",
      "Woman 0 1\n",
      "Bloodbath 0 1\n",
      "Shootouts 0 1\n",
      "Bitter 0 1\n",
      "Rivalries 0 1\n",
      "Why 0 1\n",
      "Gangsters 0 1\n",
      "are 0 1\n",
      "Killing 0 1\n",
      "Spree 0 1\n",
      "Never 0 1\n",
      "Seen 0 1\n",
      "Before 0 1\n"
     ]
    }
   ],
   "source": [
    "print('!word'+' |doc1|'+' doc2!')\n",
    "score=[]\n",
    "for i in f1:\n",
    "    if i in f2:\n",
    "        print(i+' '+'1'+' '+'1')\n",
    "        score.append([i,1,1])\n",
    "    else:\n",
    "        print(i+' '+'1'+' '+'0')\n",
    "        score.append([i,1,0])\n",
    "for i in f2:\n",
    "    if i not in f1:\n",
    "        print(i+' '+'0'+' '+'1')\n",
    "        score.append([i,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Top', 1, 0],\n",
       " ['Headlines', 1, 0],\n",
       " ['Hindi', 1, 0],\n",
       " ['imposition', 1, 0],\n",
       " ['row', 1, 0],\n",
       " ['Rijiju', 1, 0],\n",
       " ['tweets', 1, 0],\n",
       " ['old', 1, 0],\n",
       " ['video', 1, 0],\n",
       " ['Chidambaram', 1, 1],\n",
       " ['common', 1, 0],\n",
       " ['language', 1, 0],\n",
       " ['Billu', 1, 0],\n",
       " ['Barber', 1, 0],\n",
       " ['helped', 1, 0],\n",
       " ['Gujarati', 1, 0],\n",
       " ['man', 1, 0],\n",
       " ['impersonate', 1, 0],\n",
       " ['80yr-old', 1, 0],\n",
       " ['arrested', 1, 0],\n",
       " ['Delhi', 1, 1],\n",
       " ['IndiGo', 1, 0],\n",
       " ['forgets', 1, 0],\n",
       " ['Delhi-Istanbul', 1, 0],\n",
       " ['flight', 1, 0],\n",
       " ['luggage', 1, 0],\n",
       " ['Internet', 1, 0],\n",
       " ['explodes', 1, 0],\n",
       " [\"'Will\", 0, 1],\n",
       " ['Personally', 0, 1],\n",
       " ['Check', 0, 1],\n",
       " ['if', 0, 1],\n",
       " ['Required', 0, 1],\n",
       " ['CJI', 0, 1],\n",
       " ['Says', 0, 1],\n",
       " ['Ready', 0, 1],\n",
       " ['to', 0, 1],\n",
       " ['Visit', 0, 1],\n",
       " ['J', 0, 1],\n",
       " ['&', 0, 1],\n",
       " ['amp', 0, 1],\n",
       " ['K', 0, 1],\n",
       " ['Assess', 0, 1],\n",
       " ['Situation', 0, 1],\n",
       " ['After', 0, 1],\n",
       " ['Article', 0, 1],\n",
       " ['370', 0, 1],\n",
       " ['Move', 0, 1],\n",
       " ['Month', 0, 1],\n",
       " ['Ruling', 0, 1],\n",
       " ['Out', 0, 1],\n",
       " ['Mediation', 0, 1],\n",
       " ['in', 0, 1],\n",
       " ['Ayodhya', 0, 1],\n",
       " ['Case', 0, 1],\n",
       " ['Panel', 0, 1],\n",
       " ['Seeks', 0, 1],\n",
       " ['SC', 0, 1],\n",
       " [\"'s\", 0, 1],\n",
       " ['View', 0, 1],\n",
       " ['on', 0, 1],\n",
       " ['Resumption', 0, 1],\n",
       " ['of', 0, 1],\n",
       " ['Talks', 0, 1],\n",
       " ['Farooq', 0, 1],\n",
       " ['Abdullah', 0, 1],\n",
       " ['Under', 0, 1],\n",
       " ['House', 0, 1],\n",
       " ['Arrest', 0, 1],\n",
       " ['Since', 0, 1],\n",
       " ['August', 0, 1],\n",
       " ['Detained', 0, 1],\n",
       " ['Stringent', 0, 1],\n",
       " ['Public', 0, 1],\n",
       " ['Safety', 0, 1],\n",
       " ['Act', 0, 1],\n",
       " [\"'No\", 0, 1],\n",
       " ['56', 0, 1],\n",
       " ['Can', 0, 1],\n",
       " ['Stop', 0, 1],\n",
       " ['You', 0, 1],\n",
       " ['In', 0, 1],\n",
       " ['Tihar', 0, 1],\n",
       " ['Jail', 0, 1],\n",
       " ['Gets', 0, 1],\n",
       " ['Birthday', 0, 1],\n",
       " ['Letter', 0, 1],\n",
       " ['from', 0, 1],\n",
       " ['Son', 0, 1],\n",
       " ['Karti', 0, 1],\n",
       " ['The', 0, 1],\n",
       " ['Fake', 0, 1],\n",
       " ['Encounter', 0, 1],\n",
       " ['Specialist', 0, 1],\n",
       " ['Who', 0, 1],\n",
       " ['Got', 0, 1],\n",
       " ['Away', 0, 1],\n",
       " ['With', 0, 1],\n",
       " ['Sex', 0, 1],\n",
       " ['Crimes', 0, 1],\n",
       " ['Until', 0, 1],\n",
       " ['He', 0, 1],\n",
       " ['Kidnapped', 0, 1],\n",
       " ['a', 0, 1],\n",
       " ['Chennai', 0, 1],\n",
       " ['Woman', 0, 1],\n",
       " ['Bloodbath', 0, 1],\n",
       " ['Shootouts', 0, 1],\n",
       " ['Bitter', 0, 1],\n",
       " ['Rivalries', 0, 1],\n",
       " ['Why', 0, 1],\n",
       " ['Gangsters', 0, 1],\n",
       " ['are', 0, 1],\n",
       " ['Killing', 0, 1],\n",
       " ['Spree', 0, 1],\n",
       " ['Never', 0, 1],\n",
       " ['Seen', 0, 1],\n",
       " ['Before', 0, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter query:Hindi imposition\n"
     ]
    }
   ],
   "source": [
    "search_query=input('Enter query:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-2d3a24957153>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd1' is not defined"
     ]
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-fe1ba9d06821>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0md2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd2' is not defined"
     ]
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindi imposition'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq=word_tokenize(search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hindi', 'imposition']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=0\n",
    "d2=0\n",
    "ct=0\n",
    "for i in sq:\n",
    "    if i in score[ct][0]:\n",
    "        d1+=score[ct][1]\n",
    "        d2+=score[ct][2]\n",
    "        ct+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
